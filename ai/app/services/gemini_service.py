# services/gemini_service.py
from typing import List, Dict
import os
import google.generativeai as genai
from vertexai.preview.generative_models import GenerativeModel
import vertexai

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

class GeminiPromptService:
    def __init__(self):
        self.model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")

    def get_items_for_category(self, category: str, gender: str, age: int, region: str, start: str, end: str) -> List[Dict[str, str]]:
        prompt = f"""
        ì‚¬ìš©ìžì˜ ì„±ë³„ì€ {gender}, ë‚˜ì´ëŠ” {age}ì„¸ì´ë©°, ì—¬í–‰ ì§€ì—­ì€ {region}ìž…ë‹ˆë‹¤.
        ì—¬í–‰ ê¸°ê°„ì€ {start}ë¶€í„° {end}ê¹Œì§€ìž…ë‹ˆë‹¤.
        '{category}' ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ì—¬í–‰ ì§ ëª©ë¡ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        ê°ê°ì˜ ì•„ì´í…œì€ ì´ë¦„ê³¼ ìˆ˜ëŸ‰ë§Œ ì œê³µí•´ì£¼ì„¸ìš”. ì˜ˆì‹œ: ë…¸íŠ¸ë¶ 1ê°œ, ì¶©ì „ê¸° 1ê°œ
        """
        response = self.model.generate_content(prompt)
        lines = response.text.strip().split("\n")
        print("ðŸ“¦ Gemini ì‘ë‹µ:\n", response.text)
        return self._parse_lines(lines)
        

    def _parse_lines(self, lines: List[str]) -> List[Dict[str, str]]:
        result = []
        for line in lines:
            clean = line.strip("-â€¢ ").strip()
            if not clean:
                continue
            if " " in clean:
                name, qty = clean.rsplit(" ", 1)
                try:
                    quantity = int(qty.replace("ê°œ", "").strip())
                except ValueError:
                    quantity = 1
                result.append({"name": name.strip(), "quantity": quantity})
            else:
                result.append({"name": clean, "quantity": 1})
        return result
    

    
    def get_trip_concepts(self, title: str, region: str, start: str, end: str, description: str) -> List[str]:
        prompt = f"""
        ë‹¤ìŒì€ ì‚¬ìš©ìžì˜ ì—¬í–‰ ì •ë³´ìž…ë‹ˆë‹¤:

        - ì—¬í–‰ ì œëª©: {title}
        - ì—¬í–‰ ì§€ì—­: {region}
        - ì—¬í–‰ ê¸°ê°„: {start} ~ {end}
        - ì—¬í–‰ ì„¤ëª…: {description}

        ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§ êµ¬ì„±ì— ë„ì›€ì´ ë˜ëŠ” **ì—¬í–‰ ì»¨ì…‰ íƒœê·¸**ë¥¼ ë‹¤ìŒ 6ê°€ì§€ ë²”ì£¼ì—ì„œ ê°ê° 1~2ê°œì”© ìƒì„±í•´ì£¼ì„¸ìš”. ê° íƒœê·¸ëŠ” í•´ë‹¹ ì—¬í–‰ ì •ë³´ì— ìµœëŒ€í•œ ë§žì¶°ì„œ ì‹¤ì œ ì˜ë¯¸ ìžˆëŠ” ìš”ì†Œë§Œ ê³¨ë¼ì£¼ì„¸ìš”.

        ë²”ì£¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

        1. ë™ë°˜ìž ê´€ë ¨ (ì˜ˆ: ê°€ì¡±, ì•„ì´ ë™ë°˜, ì—°ì¸, ë°˜ë ¤ë™ë¬¼ ë“±)
        2. ê³„ì ˆ/ë‚ ì”¨ ê´€ë ¨ (ì˜ˆ: ì—¬ë¦„, ìž¥ë§ˆì² , ë”ìš´ ë‚ ì”¨, ì¼êµì°¨ í¼ ë“±)
        3. í™œë™ ì„±ê²© ê´€ë ¨ (ì˜ˆ: ë„ì‹œ ê´€ê´‘, í•´ë³€ í™œë™, íŠ¸ë ˆí‚¹, ìˆ˜ì˜, ë Œí„°ì¹´ ì´ìš©, ëŒ€ì¤‘êµí†µ ë“±)
        4. ìˆ™ë°• ìŠ¤íƒ€ì¼ ê´€ë ¨ (ì˜ˆ: í˜¸í…” ìˆ™ë°•, ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤, ìº í•‘ ë“±)
        5. ì§ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìžˆëŠ” ìƒí™© (ì˜ˆ: ìž¥ê±°ë¦¬ ì´ë™, ì•½ ë³µìš©, ìƒë¦¬ ì˜ˆì •, ì•„ì´ìš©í’ˆ í•„ìš” ë“±)
        6. ì§€ì—­ íŠ¹ì„± ê´€ë ¨ (ì˜ˆ: ì„¬ ì§€ì—­, êµ­ë‚´ì—¬í–‰, êµ­ì™¸ì—¬í–‰, ëŒ€ë„ì‹œ, êµí†µ ë¶ˆíŽ¸, ì–¸ì–´ ìž¥ë²½ ë“±)

        ì•„ëž˜ ì¡°ê±´ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:

        - ê° ë²”ì£¼ëŠ” ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ê° ë²”ì£¼ë³„ë¡œ 1~2ê°œì˜ íƒœê·¸ë§Œ ìž‘ì„±í•´ì£¼ì„¸ìš”.
        - íƒœê·¸ëŠ” ì¤‘ë³µë˜ì§€ ì•Šì•„ì•¼ í•˜ë©°, **'êµ­ë‚´ì—¬í–‰'/'êµ­ì™¸ì—¬í–‰'**ì„ ì§€ì—­(region)ì„ ê¸°ì¤€ìœ¼ë¡œ ì •í™•ížˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”.

        ì˜ˆì‹œ ì¶œë ¥:
        ë™ë°˜ìž: ê°€ì¡±, ì•„ì´ ë™ë°˜  
        ê³„ì ˆ/ë‚ ì”¨: ì—¬ë¦„, ìž¥ë§ˆì²   
        í™œë™ ì„±ê²©: í•´ë³€ í™œë™, ë Œí„°ì¹´ ì´ë™  
        ìˆ™ë°• ìŠ¤íƒ€ì¼: í˜¸í…” ìˆ™ë°•  
        ì§ ì˜í–¥ ìš”ì†Œ: ì•„ì´ìš©í’ˆ í•„ìš”, ìž¥ê±°ë¦¬ ì´ë™  
        ì§€ì—­ íŠ¹ì„±: ì„¬ ì§€ì—­, êµ­ë‚´ì—¬í–‰  
        """

        response = self.model.generate_content(prompt)
        print("ðŸ·ï¸ Gemini ì¹´í…Œê³ ë¦¬ë³„ íƒœê·¸ ì‘ë‹µ:\n", response.text)

        # ê²°ê³¼ íŒŒì‹±
        tags = []
        for line in response.text.strip().split("\n"):
            if ":" in line:
                tag_values = line.split(":", 1)[1]
                tags += [t.strip() for t in tag_values.split(",") if t.strip()]
        return tags
    

vertexai.init(project="packit-463009", location="us-central1")

# ì¶”ì²œ í•¨ìˆ˜
def get_packing_recommendation(prompt: str) -> str:
    model = GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text